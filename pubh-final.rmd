```{r}
library("rgdal")
library("raster")
library("sf")
library("leafsync")
library("dplyr")
library("ggplot2")
library("stars")
library(spatialEco)
library(spatstat.random)
library(data.table)
library(geoR)
library(RColorBrewer)
library(spdep)
library(spatialreg)
library(classInt)
library(raster)
library(rgeos)
library(landscapemetrics)
library(nimble)
library(coda)
```


```{r}
# read in data
cwd.dat<-read.table(
  "./data/wi-dat.csv",
  sep=",", header=TRUE)
# deer.hrvst.dat <- read.table("./data/deer-harvest-master.csv",
#                             sep=",",header=TRUE)
```

```{r}

cwd.agg <- data.frame(wsi=c(unique(cwd.dat.s$wsi)), cwd.pos=0, n=0)

for(i in 1:nrow(cwd.dat.s)){
  for(k in 1:nrow(cwd.agg)){
  if(cwd.dat.s[i,]$wsi == cwd.agg[k,]$wsi)
     cwd.agg[k,]$cwd.pos = cwd.agg[k,]$cwd.pos + cwd.dat.s[i,]$cwdPositive
    cwd.agg[k,]$n = cwd.agg[k,]$n + 1
  }
}

ggplot(cwd.agg, aes(wsi, cwd.pos)) +
  geom_line() +
    theme(panel.grid=element_blank(),
        panel.background = element_blank())


ggplot(cwd.dat.s, aes(wsi)) +
  geom_density() +
    theme(panel.grid=element_blank(),
        panel.background = element_blank())

```

```{r}
cwd.agg$prop.pos <- cwd.agg$cwd.pos/cwd.agg$n
wsi.mod<-lm(cwd.pos~wsi, cwd.agg)
(wsi.mod)
plot(wsi.mod)
```

```{r}
wiShp<-st_read("./data/shapefiles/PLSS_Townships/PLSS_Townships.shp")
wiCountyShp <- st_read("./data/shapefiles/County_Boundaries_24K/County_Boundaries_24K.shp")
plot(wiCountyShp)
```
```{r}

# now we want to subset our county data by the study area
wiCountyStudy<-subset(wiCountyShp, COUNTY_FIP %in% unique(cwd.dat.s$fipsCode))

# next we're going to turn this into an extent
# let's first make sure we're working with the same CRS
wiCountyStudy<-st_transform(wiCountyStudy, crs(wiShp))
studyarea<-st_crop(wiShp, wiCountyStudy)
plot(studyarea)
```
```{r}
# 
# cwd.dat<-read.table(
#   "./data/wi-dat.csv",
#   sep=",", header=TRUE)
# wiShp<-st_read("./data/shapefiles/WI_PLSSTownships_1996/plss_townships/WI_PLSSTownships_1996.shp")
cwd.dat <- cwd.dat%>%subset(year >= 2013)

# wiShp$studyarea <- 0

# clean the cwd data
# for(i in 1:nrow(cwd.dat)){
#   if(cwd.dat[i,]$rangeDir == "East"){
#     cwd.dat[i,]$rangeDir = "E"
#   }
#   cwd.dat[i,]$rangeDir == "W"
# }
# wiShp.e<-subset(wiShp, DIR==4)
# cwd.dat<-na.omit(cwd.dat)
# study.area to subset data for class 

# for(i in 1:nrow(wiShp.e)){
#   for(j in 1:nrow(cwd.dat)){
#   if(wiShp.e[i,]$TWP == cwd.dat[j,]$township){
#     if(wiShp.e[i,]$RNG == cwd.dat[j,]$range){
#         wiShp.e[i,]$study.area <- 1
#         }
#       }
#     }
#   }

# next we want to subset our data
#wiShp.s<-subset(wiShp.e, study.area==1)
# test
# study_shape<-subset(wiShp.e, study.area==1)

# do this when we want plot
# study_shape<-as(study_shape, "Spatial")

# plot(as(study_shape, "Spatial"))
```

```{r}

wi.coords<-coordinates(as(studyarea, "Spatial"))

studyarea$cwd.pos <- 0
studyarea$county <- 0
studyarea$year <- 0

for(i in 1:nrow(studyarea)){
  for(j in 1:nrow(cwd.dat.s)){
    if(studyarea[i,]$TWP == cwd.dat.s[j,]$township &
       studyarea[i,]$RNG == cwd.dat.s[j,]$range){
          studyarea[i,]$cwd.pos = studyarea[i,]$cwd.pos + cwd.dat.s[j,]$cwdPositive
          studyarea[i,]$county = cwd.dat.s[j,]$county
        }
      }
}

# next we want to attach our deer data to the subset
# so let's create a few variables in our spatial dataframe
deer.knn <- knearneigh(wi.coords)
deer.knn2nb = knn2nb(deer.knn)
deer.list = nbdists(deer.knn2nb, wi.coords)
deer.dist.vec <- unlist(deer.list)
upper.bound.75<-0.50*max(deer.dist.vec)
deer.dnn.nb.75<-dnearneigh(wi.coords, d1=0, d2=upper.bound.75)
deer.dnn.listw.75 <- nb2listw(deer.dnn.nb.75, style="B", zero.policy=TRUE)
deer.dnn.car.out.75 <- spautolm(studyarea$cwd.pos~NULL,
                                data=studyarea$geometry, family="CAR", listw=deer.dnn.listw.75, zero.policy = TRUE)
deer.dnn.car.fitted.75 = fitted(deer.dnn.car.out.75)

studyarea.rook.nb<-poly2nb(studyarea, queen="TRUE")
studyarea.rook.listw = nb2listw(studyarea.rook.nb, style="W", zero.policy=TRUE)
study.area.moran.out = moran.test(studyarea$cwd.pos, listw=studyarea.rook.listw, zero.policy=TRUE)

studyarea$fitted.car <- deer.dnn.car.fitted.75
brks = seq(-4,12, 1)
color.pallete = rev(brewer.pal(length(brks),"RdBu"))
# create 75% of max dist breaks
class.fitted.car.75 = classIntervals(var=studyarea$fitted.car, n=length(brks), style="fixed", fixedBreaks=brks, dataPrecision=1)
color.code.fitted.car.75 = findColours(class.fitted.car.75, color.pallete)

# we need to extract the max and min coordinates
min.coord<-which.min(wi.coords)
max.coord<-which.max(wi.coords)
ggplot(studyarea$geometry, aes(fill=studyarea$fitted.car, ylim=)) +
  geom_sf() +
  guides(fill=guide_legend(title="cwd positive"), color=guide_legend(show=FALSE)) +
  theme(panel.grid=element_blank(),
        panel.background = element_blank()) +
  xlim(x.min.max) +
  ylim(y.min.max)

summary(study.area.moran.out
        )

studyarea.rook.car.out = spautolm(cwd.pos~NULL, data=studyarea, family="CAR", listw=studyarea.rook.listw, zero.policy=TRUE)
summary(studyarea.rook.car.out)
```

```{r}
# now we need to build a new spatial dataframe to hold our temporal data
# rng<-studyarea$RNG
# twp<-studyarea$TWP
# geometry<-studyarea$geometry
# rtg <- cbind(rng, twp, geometry)
# years.shapes<-expand.grid(rtg,year.samp)
# plot(years.shapes)

```

```{r}
wishp.shp<-readOGR("./data/shapefiles/PLSS_Townships", layer="PLSS_Townships")
wiCountyShp <- readOGR("./data/shapefiles/County_Boundaries_24K", layer="County_Boundaries_24K")
wiCountyShp <- subset(wiCountyShp, COUNTY_FIP %in% unique(cwd.dat.s$fipsCode))
wiCountyShp<-spTransform(wiCountyShp, CRS(proj4string(wishp.shp)))
wiTwnshpShp<-intersect(wiCountyShp,wishp.shp)
lc<-raster("./data/raster/WI_NLCD_2011/WI_NLCD_2011/nlcd_wi_utm16.tif")
## now we can use mask
wiTwnshpShp<-spTransform(wiTwnshpShp, crs(lc))
lc.studyarea <-  crop(lc, wiTwnshpShp)
lc.evergreen <- lc.studyarea==42
plot(lc.evergreen)
```

```{r}
n.evergreen <- rep(0, nrow(wiTwnshpShp))
evergreen.clumps <- rep(0, nrow(wiTwnshpShp))
cwd.pos <- rep(0, nrow(wiTwnshpShp))
for(i in 1:nrow(wiTwnshpShp)){
 twnshp<-crop(lc.evergreen, wiTwnshpShp[i,])
 clump<-lsm_c_clumpy(twnshp)
   evergreen.clumps[i] <- if(!is.null(clump[2,]$value)) clump[2,]$value else 2
 for(j in 1:nrow(twnshp)){
   n.evergreen[i] = n.evergreen[i] + sum(twnshp[j,])
   }
}
wiTwnshpShp$n.evergrn <- n.evergreen
wiTwnshpShp$cwd.pos <- 0
wiTwnshpShp$evergreen.clump <- evergreen.clumps
cwd.dat <- na.omit(cwd.dat)
for(i in 1:nrow(wiTwnshpShp)){
  for(j in 1:nrow(cwd.dat)){
    if(wiTwnshpShp[i,]$TWP == cwd.dat[j,]$township &
       wiTwnshpShp[i,]$RNG == cwd.dat[j,]$range){
          cwd.pos[i] = cwd.pos[i] + cwd.dat[j,]$cwdPositive
        }
      }
}
wiTwnshpShp$cwd.pos <- cwd.pos
wiTwnshpShp.subset<-subset(wiTwnshpShp, cwd.pos > 0)
plot(wiTwnshpShp.subset$cwd.pos~wiTwnshpShp.subset$evergreen.clump)
wisf<-st_as_sf(wiTwnshpShp)
ggplot(wisf$geometry, aes(fill=wisf$evergreen.clump)) + 
  geom_sf()
```

```{r, CAR model}
wi.coords <- coordinates()
deer.knn <- knearneigh(wi.coords)
deer.knn2nb = knn2nb(deer.knn)
deer.list = nbdists(deer.knn2nb, wi.coords)
deer.dist.vec <- unlist(deer.list)
upper.bound.75<-0.50*max(deer.dist.vec)
deer.dnn.nb.75<-dnearneigh(wi.coords, d1=0, d2=upper.bound.75)
deer.dnn.listw.75 <- nb2listw(deer.dnn.nb.75, style="B", zero.policy=TRUE)
deer.dnn.car.out.75 <- spautolm(studyarea$cwd.pos~NULL,
                                data=studyarea$geometry, family="CAR", listw=deer.dnn.listw.75, zero.policy = TRUE)
deer.dnn.car.fitted.75 = fitted(deer.dnn.car.out.75)

studyarea.rook.nb<-poly2nb(studyarea, queen="TRUE")
studyarea.rook.listw = nb2listw(studyarea.rook.nb, style="W", zero.policy=TRUE)
study.area.moran.out = moran.test(studyarea$cwd.pos, listw=studyarea.rook.listw, zero.policy=TRUE)

studyarea$fitted.car <- deer.dnn.car.fitted.75
brks = seq(-4,12, 1)
color.pallete = rev(brewer.pal(length(brks),"RdBu"))
# create 75% of max dist breaks
class.fitted.car.75 = classIntervals(var=studyarea$fitted.car, n=length(brks), style="fixed", fixedBreaks=brks, dataPrecision=1)
color.code.fitted.car.75 = findColours(class.fitted.car.75, color.pallete)

# we need to extract the max and min coordinates
min.coord<-which.min(wi.coords)
max.coord<-which.max(wi.coords)
ggplot(studyarea$geometry, aes(fill=studyarea$fitted.car, ylim=)) +
  geom_sf() +
  guides(fill=guide_legend(title="cwd positive"), color=guide_legend(show=FALSE)) +
  theme(panel.grid=element_blank(),
        panel.background = element_blank()) +
  xlim(x.min.max) +
  ylim(y.min.max)

summary(study.area.moran.out
        )

studyarea.rook.car.out = spautolm(cwd.pos~NULL, data=studyarea, family="CAR", listw=studyarea.rook.listw, zero.policy=TRUE)
summary(studyarea.rook.car.out)


```
```{r, nimble spatial model}
# 2012 - 2013
# 2013 - 2014
# 2014 - 2015
# 2015 - 2016
# 2016 - 2017
# 2017 - 2018
# 2018 - 2019
# 2019 - 2020
# 2020 - 2021
# 2021 - 2022
Dane <- c(13, 50, 29, 12, 11, 24, 23, 8, 20, 18)
Columbia <- c(19, 55, 30, 14, 13, 25, 28, 10, 21, 21)
Dodge <- c(16, 53, 30, 12,  12, 25, 25, 9, 20, 18)
Jefferson <- c(12, 47, 29, 11, 10, 24, 21, 5, 20, 15)
wsi <- data.frame(Dane=Dane, Columbia=Columbia,
             Dodge=Dodge, Jefferson=Jefferson)
year.samp <- c(2013,2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022)
cwd.dat <- cwd.dat%>%subset(year >= 2013)
cwd.dat$wsi <- 0
# 2014 - 2022
# years <- c(1:8)
# counties <-c("dane", "columbia", "dodge", "jefferson")
# cwd.p <- 0
# for(i in 1:nrow(cwd.dat)){
#   for( j in 1:length(year.samp)){
#         if(cwd.dat[i,]$year == year.samp[j]){
#           if(cwd.dat[i,]$county == "Dane"){
#             cwd.dat[i,]$wsi <- wsi[j,]$Dane
#           }
#           if(cwd.dat[i,]$county == "Dodge"){
#             cwd.dat[i,]$wsi <- wsi[j,]$Dodge
#           }
#           if(cwd.dat[i,]$county == "Jefferson"){
#             cwd.dat[i,]$wsi <- wsi[j,]$Jefferson
#           }
#           if(cwd.dat[i,]$county == "Columbia"){
#             cwd.dat[i,]$wsi <- wsi[j,]$Columbia
#           }
#             (cwd.dat.s[i,]$county)
#         }
#   }
# }
# let's average over the sampling period to get the expected number of positive cases
# for each PLSS township
cwd.expected <- rep(0, nrow(wiTwnshpShp))
cwd.expected <- cwd.pos / length(year.samp)

wiTwnshpShp$cwd.expected <- cwd.expected

W.nb <- poly2nb(wiTwnshpShp)
W <- nb2WB(W.nb)
## Specify the hierarchical model
# 
# dZIP <- nimbleFunction(
#  run = function(x = integer(), lambda = double(), 
#                 zeroProb = double(), log = logical(0, default = 0)) {
#    returnType(double())
#    ## First handle non-zero data
#    if (x != 0) {
#        ## return the log probability if log = TRUE
#        if (log) return(dpois(x, lambda, log = TRUE) + log(1 - zeroProb))
#        ## or the probability if log = FALSE
#       else return((1 - zeroProb) * dpois(x, lambda, log = FALSE))
#    }
#    ## From here down we know x is 0
#    totalProbZero <- zeroProb + (1 - zeroProb) * dpois(0, lambda, log = FALSE)
#    if (log) return(log(totalProbZero))
#    return(totalProbZero)
#  })
# 
# registerDistributions(list(
#     dZIP = list(
#         BUGSdist = "dZIP(lambda, zeroProb)",
#         discrete = TRUE,
#         range = c(0, Inf),
#         types = c('value = integer()', 'lambda = double()', 'zeroProb = double()')
#      )))

# TODO: AVERAGE over years for WSI
dZIP <- nimbleFunction(
 run = function(x = integer(), lambda = double(),
                zeroProb = double(), log = logical(0, default = 0)) {
   returnType(double())
   ## First handle non-zero data
   if (x != 0) {
       ## return the log probability if log = TRUE
       if (log) return(dpois(x, lambda, log = TRUE) + log(1 - zeroProb))
       ## or the probability if log = FALSE
      else return((1 - zeroProb) * dpois(x, lambda, log = FALSE))
   }
   ## From here down we know x is 0
   totalProbZero <- zeroProb + (1 - zeroProb) * dpois(0, lambda, log = FALSE)
   if (log) return(log(totalProbZero))
   return(totalProbZero)
 })

registerDistributions(list(
    dZIP = list(
        BUGSdist = "dZIP(lambda, zeroProb)",
        discrete = TRUE,
        range = c(0, Inf),
        types = c('value = integer()', 'lambda = double()', 'zeroProb = double()')
     )))

modelcode <- nimbleCode({
  # likelihood
  
  for (i in 1 : N) {
        
    
    
      N[i] ~ dZIP(mu[i], p[i])
        # our expectation can simply be the average of the given sampling unit over the study period
       # why not try the average for particular year across all sampling units -- later we can try to make it the average across across a cluster of sampling units 
        # WSI is our WSI index for a particular county in year i
        log(mu[i]) <- E[i] + beta0 + beta1*clumps[i] + phi[i] + theta[i]
        theta[i] ~ dnorm(0.0, prec.h)
        eta[i] <- theta[i] + phi[i]
  }
  
    # CAR model for spatial random effects
    phi[1:N] ~ dcar_normal(adj[1:L], weights[1:L], num[1:N], prec.c, zero_mean=0)
    
    ## priors
    beta0 ~ dnorm(0.0, sd = 100)  # vague prior on grand intercept
    beta1 ~ dunif(0,100)  # vague prior on clumpiness covariate effect
    # beta2 ~ dnorm(0.0, sd = 100) # vague prior on on clumpiness covariate effect 
    prec.h ~ dgamma(0.001, 0.001)  
    prec.c ~ dgamma(0.1, 0.1)  
    
    # other prior choices for spatial/nonspatial precision
    # prec.h ~ dgamma(0.32761, 0.181)
    # prec.c ~ dgamma(0.1, 0.1)
    
    # prec.h ~ dgamma(3.2761,1.81)
    # prec.c ~ dgamma(1.0,1.0)

    sigma2 <- 1/prec.h
    tau2 <- 1/prec.c
    
    ## calculate alpha
    sd.h <- sd(theta[1:N]) # marginal SD of heterogeneity effects
    sd.c <- sd(phi[1:N])   # marginal SD of clustering (spatial) effects
    alpha <- sd.c/(sd.h + sd.c)
})

p<-runif(nrow(wiTwnshpShp), 0, 1)
## Specify data and initial values
constants <- list(N = nrow(wiTwnshpShp), p=p,L = length(W$adj), adj=W$adj, weights=W$weights, num=W$num,
                  E = wiTwnshpShp$cwd.expected, clumps=wiTwnshpShp$n.evergrn)
data <- list(y = wiTwnshpShp$cwd.pos)
inits <- list(beta0 = 0, beta1 = 0, prec.h = 1, prec.c = 1)


## Build/Compile model, including steps: 
## (1) build model (2) compile model in C++ 
## (3) specify MCMC parameters to collect and create MCMC algorithm
cwdspatmodel <- nimbleModel(modelcode, constants = constants, data = data, inits = inits)
c.cwdspatmodel <- compileNimble(cwdspatmodel)

confMC <- configureMCMC(cwdspatmodel, monitors = c('beta0','beta1','sigma2','tau2','eta','alpha'),  enableWAIC = TRUE)
cwdspatmcmc <- buildMCMC(confMC)
c.cwdspatmcmc <- compileNimble(cwdspatmcmc, project = cwdspatmodel)


## Run MCMC
mcmc.out <- runMCMC(c.cwdspatmcmc, niter=60000, nburnin=50000, thin=5, nchains=3, WAIC=TRUE)

## convert post samples as mcmc.list object and diagnose convergence using coda functions
post.samples <- mcmc.list(sapply(mcmc.out$samples,as.mcmc,simplify=FALSE))
pars <- c("alpha","beta1","tau2","sigma2","eta[1]")
plot(post.samples[,pars], trace=TRUE, density=FALSE)
gelman.plot(post.samples[,pars])
autocorr.plot(post.samples[,pars])

## posterior summary
summary(post.samples[,pars])

## model assessment using WAIC value
mcmc.out$WAIC
```

```{r, temporal model}

pos <- wiTwnshpShp %>% subset(cwd.pos > 0)
pos$bin<-cut(pos$n.evergrn,breaks=c(499, 999, 1499, 1999, 2499, 2999, 3499, 4000))
wi<-st_as_sf(wiTwnshpShp)
ggplot(wi, aes(wi$n.evergrn)) +
  geom_density() +
  theme(panel.grid=element_blank(),
        panel.background = element_blank())
```